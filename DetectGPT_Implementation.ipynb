{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets\n",
        "from datasets import load_dataset\n",
        "\n",
        "# Load the XSum dataset\n",
        "xsum_dataset = load_dataset(\"xsum\")\n",
        "xsum_test = xsum_dataset['test']"
      ],
      "metadata": {
        "id": "SSU0A8gh-zTN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "455daa9c-5aba-4d3e-b5f2-17e7477fc8cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (2.18.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.13.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.25.2)\n",
            "Requirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (14.0.2)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets) (0.6)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.2)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.4.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec[http]<=2024.2.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.3)\n",
            "Requirement already satisfied: huggingface-hub>=0.19.4 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.20.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.4->datasets) (4.10.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2024.2.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/datasets/load.py:1461: FutureWarning: The repository for xsum contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/xsum\n",
            "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
            "Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##Get Log-likelihood\n",
        "import torch\n",
        "tokenizer_ll = AutoTokenizer.from_pretrained(\"gpt2\")\n",
        "model_ll = AutoModelForCausalLM.from_pretrained(\"gpt2\")\n",
        "def get_log_likelihood(text):\n",
        "  with torch.no_grad():\n",
        "      tokenized = tokenizer_ll(text, return_tensors=\"pt\")\n",
        "      labels = tokenized.input_ids\n",
        "      ll = -model_ll(**tokenized, labels=labels).loss.item()\n",
        "      return ll\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "taOaonxO-sb9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline, AutoTokenizer, AutoModelForCausalLM\n",
        "\n",
        "# Load tokenizer and model\n",
        "generate_tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n",
        "generate_model = AutoModelForCausalLM.from_pretrained(\"gpt2\")\n",
        "\n",
        "def generate_text(text):\n",
        "  # Define your prompt\n",
        "\n",
        "  prompt = \" \".join(text.split()[:30])\n",
        "  # Tokenize the prompt\n",
        "  inputs = generate_tokenizer(prompt, return_tensors=\"pt\")\n",
        "\n",
        "  # Generate text\n",
        "  output = generate_model.generate(\n",
        "      inputs.input_ids,\n",
        "      max_length=300,  # Adjust the length as needed\n",
        "      temperature=0.7,  # Adjust the temperature for more or less randomness\n",
        "      top_k=50,  # Adjust for diversity\n",
        "      top_p=0.95,  # Adjust for diversity\n",
        "      do_sample=True,\n",
        "      num_return_sequences=1  # Number of sequences to generate\n",
        "  )\n",
        "\n",
        "  # Decode the generated output\n",
        "  generated_text = generate_tokenizer.decode(output[0], skip_special_tokens=True)\n",
        "  return generated_text\n"
      ],
      "metadata": {
        "id": "DXH3IFqxyc2X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "def mask_text(text, mask_percentage):\n",
        "    # Tokenize the text into words\n",
        "    words = text.split()\n",
        "\n",
        "    # Calculate the number of two-word samples to mask\n",
        "    num_samples_to_mask = int(len(words) * mask_percentage / 2)\n",
        "\n",
        "    # Create a copy of the words list to avoid modifying the original text\n",
        "    masked_text = words.copy()\n",
        "\n",
        "    # Generate indices of two-word samples to mask\n",
        "    indices_to_mask = random.sample(range(len(words) - 1), num_samples_to_mask)\n",
        "\n",
        "    # Mask out the selected two-word samples\n",
        "    for index in indices_to_mask:\n",
        "        masked_text[index] = \"[MASK]\"\n",
        "        masked_text[index + 1] = \"[MASK]\"\n",
        "\n",
        "    # Join the masked words back into a sentence\n",
        "    masked_sentence = \" \".join(masked_text)\n",
        "\n",
        "    return masked_sentence\n",
        "\n",
        "# Example text\n",
        "#text = \"Prison Link Cymru had 1,099 referrals in 2015-16 and said some ex-offenders were living rough for up to a year before finding suitable accommodation. Workers at the charity claim investment.\"\n"
      ],
      "metadata": {
        "id": "SgF6IYxY0ZJw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline, AutoTokenizer, AutoModelForMaskedLM\n",
        "# Load tokenizer and model for masked language modeling\n",
        "masked_tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "masked_model = AutoModelForMaskedLM.from_pretrained(\"bert-base-uncased\")\n",
        "\n",
        "def generate_filled_text(masked_text):\n",
        "\n",
        "\n",
        "    # Tokenize the masked text\n",
        "    tokenized_text = masked_tokenizer(masked_text, return_tensors=\"pt\")\n",
        "\n",
        "    # Mask filling pipeline\n",
        "    fill_mask = pipeline(\"fill-mask\", model=masked_model, tokenizer=masked_tokenizer)\n",
        "\n",
        "    # Generate predictions for masked tokens\n",
        "    filled_text = masked_text\n",
        "    for prediction in fill_mask(masked_text):\n",
        "        filled_text = filled_text.replace(\"[MASK]\", prediction[0][\"token_str\"], 1)\n",
        "\n",
        "    return filled_text\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ULcmzFri0x_8",
        "outputId": "e98c75c3-2055-4b2e-9507-ed8100bbbb9c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "human = []\n",
        "ai = []\n",
        "for i in range(100):\n",
        "\n",
        "  text = xsum_test[i]['document']\n",
        "  #Set to less than 512 tokens\n",
        "  text = \" \".join(text.split()[:350])\n",
        "\n",
        "  masked_test_text = mask_text(text, 0.15)\n",
        "  filled_test_text = generate_filled_text(masked_test_text)\n",
        "\n",
        "  generated_text = generate_text(text)\n",
        "  masked_generated_text = mask_text(generated_text, 0.15)\n",
        "  filled_generated_text = generate_filled_text(masked_generated_text)\n",
        "\n",
        "\n",
        "\n",
        "  humanscore = get_log_likelihood(text) - get_log_likelihood(filled_test_text)\n",
        "  aiscore = get_log_likelihood(generated_text) - get_log_likelihood(filled_generated_text)\n",
        "\n",
        "  human.append(humanscore)\n",
        "  ai.append(aiscore)\n",
        "  print(i)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GirfzDd-p2D9",
        "outputId": "3831ea18-cb53-4fcf-c417-1e2d573f84f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "11\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "12\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "13\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "14\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "15\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "16\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "17\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "18\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "19\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "21\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "22\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "26\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "27\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "28\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "29\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "31\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "32\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "33\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "34\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "35\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "36\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "37\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "38\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "39\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "40\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "41\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "42\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "43\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "44\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "45\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "46\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "47\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "48\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "49\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "51\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "52\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "53\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "54\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "55\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "56\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "57\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "58\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "59\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "60\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "61\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "62\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "63\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "64\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "65\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "66\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "67\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "68\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "69\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "70\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "71\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "72\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "73\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "74\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "75\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "76\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "77\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "78\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "79\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "80\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "81\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "82\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "83\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "84\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "85\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "86\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "87\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "88\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "89\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "90\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "91\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "92\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "93\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "94\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "95\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "96\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "97\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "98\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "99\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Define the data\n",
        "\n",
        "\n",
        "# Set the number of bins\n",
        "num_bins = 10\n",
        "\n",
        "# Create the histogram\n",
        "plt.hist(human, bins=num_bins, alpha=0.5, label='human')\n",
        "plt.hist(ai, bins=num_bins, alpha=0.5, label='ai')\n",
        "\n",
        "# Add labels and title\n",
        "plt.xlabel('Log Probability Change')\n",
        "plt.ylabel('Frequency')\n",
        "plt.title('Histogram LL')\n",
        "\n",
        "\n",
        "# Add legend\n",
        "plt.legend()\n",
        "\n",
        "# Show the plot\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "IEwlUkQIq_V8",
        "outputId": "4ff5ad12-626b-4ad1-97f5-a01a95e2e8bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "---DetectGPT code snippet---\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import datasets\n",
        "import transformers\n",
        "import re\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import tqdm\n",
        "import random\n",
        "from sklearn.metrics import roc_curve, precision_recall_curve, auc\n",
        "import argparse\n",
        "import datetime\n",
        "import os\n",
        "import json\n",
        "import functools\n",
        "import custom_datasets\n",
        "from multiprocessing.pool import ThreadPool\n",
        "import time\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def tokenize_and_mask(text, span_length, pct, ceil_pct=False):\n",
        "    tokens = text.split(' ')\n",
        "    mask_string = '<<<mask>>>'\n",
        "\n",
        "    n_spans = pct * len(tokens) / (span_length + args.buffer_size * 2)\n",
        "    if ceil_pct:\n",
        "        n_spans = np.ceil(n_spans)\n",
        "    n_spans = int(n_spans)\n",
        "\n",
        "    n_masks = 0\n",
        "    while n_masks < n_spans:\n",
        "        start = np.random.randint(0, len(tokens) - span_length)\n",
        "        end = start + span_length\n",
        "        search_start = max(0, start - args.buffer_size)\n",
        "        search_end = min(len(tokens), end + args.buffer_size)\n",
        "        if mask_string not in tokens[search_start:search_end]:\n",
        "            tokens[start:end] = [mask_string]\n",
        "            n_masks += 1\n",
        "\n",
        "    # replace each occurrence of mask_string with <extra_id_NUM>, where NUM increments\n",
        "    num_filled = 0\n",
        "    for idx, token in enumerate(tokens):\n",
        "        if token == mask_string:\n",
        "            tokens[idx] = f'<extra_id_{num_filled}>'\n",
        "            num_filled += 1\n",
        "    assert num_filled == n_masks, f\"num_filled {num_filled} != n_masks {n_masks}\"\n",
        "    text = ' '.join(tokens)\n",
        "    return text\n",
        "\n",
        "\n",
        "def count_masks(texts):\n",
        "    return [len([x for x in text.split() if x.startswith(\"<extra_id_\")]) for text in texts]\n",
        "\n",
        "\n",
        "# replace each masked span with a sample from T5 mask_model\n",
        "def replace_masks(texts):\n",
        "    n_expected = count_masks(texts)\n",
        "    stop_id = mask_tokenizer.encode(f\"<extra_id_{max(n_expected)}>\")[0]\n",
        "    tokens = mask_tokenizer(texts, return_tensors=\"pt\", padding=True).to(DEVICE)\n",
        "    outputs = mask_model.generate(**tokens, max_length=150, do_sample=True, top_p=args.mask_top_p, num_return_sequences=1, eos_token_id=stop_id)\n",
        "    return mask_tokenizer.batch_decode(outputs, skip_special_tokens=False)\n",
        "\n",
        "\n",
        "def extract_fills(texts):\n",
        "    # remove <pad> from beginning of each text\n",
        "    texts = [x.replace(\"<pad>\", \"\").replace(\"</s>\", \"\").strip() for x in texts]\n",
        "\n",
        "    # return the text in between each matched mask token\n",
        "    extracted_fills = [pattern.split(x)[1:-1] for x in texts]\n",
        "\n",
        "    # remove whitespace around each fill\n",
        "    extracted_fills = [[y.strip() for y in x] for x in extracted_fills]\n",
        "\n",
        "    return extracted_fills\n",
        "\n",
        "\n",
        "def apply_extracted_fills(masked_texts, extracted_fills):\n",
        "    # split masked text into tokens, only splitting on spaces (not newlines)\n",
        "    tokens = [x.split(' ') for x in masked_texts]\n",
        "\n",
        "    n_expected = count_masks(masked_texts)\n",
        "\n",
        "    # replace each mask token with the corresponding fill\n",
        "    for idx, (text, fills, n) in enumerate(zip(tokens, extracted_fills, n_expected)):\n",
        "        if len(fills) < n:\n",
        "            tokens[idx] = []\n",
        "        else:\n",
        "            for fill_idx in range(n):\n",
        "                text[text.index(f\"<extra_id_{fill_idx}>\")] = fills[fill_idx]\n",
        "\n",
        "    # join tokens back into text\n",
        "    texts = [\" \".join(x) for x in tokens]\n",
        "    return texts\n",
        "\n",
        "\n",
        "def perturb_texts_(texts, span_length, pct, ceil_pct=False):\n",
        "    if not args.random_fills:\n",
        "        masked_texts = [tokenize_and_mask(x, span_length, pct, ceil_pct) for x in texts]\n",
        "        raw_fills = replace_masks(masked_texts)\n",
        "        extracted_fills = extract_fills(raw_fills)\n",
        "        perturbed_texts = apply_extracted_fills(masked_texts, extracted_fills)\n",
        "\n",
        "        # Handle the fact that sometimes the model doesn't generate the right number of fills and we have to try again\n",
        "        attempts = 1\n",
        "        while '' in perturbed_texts:\n",
        "            idxs = [idx for idx, x in enumerate(perturbed_texts) if x == '']\n",
        "            print(f'WARNING: {len(idxs)} texts have no fills. Trying again [attempt {attempts}].')\n",
        "            masked_texts = [tokenize_and_mask(x, span_length, pct, ceil_pct) for idx, x in enumerate(texts) if idx in idxs]\n",
        "            raw_fills = replace_masks(masked_texts)\n",
        "            extracted_fills = extract_fills(raw_fills)\n",
        "            new_perturbed_texts = apply_extracted_fills(masked_texts, extracted_fills)\n",
        "            for idx, x in zip(idxs, new_perturbed_texts):\n",
        "                perturbed_texts[idx] = x\n",
        "            attempts += 1\n",
        "    else:\n",
        "        if args.random_fills_tokens:\n",
        "            # tokenize base_tokenizer\n",
        "            tokens = base_tokenizer(texts, return_tensors=\"pt\", padding=True).to(DEVICE)\n",
        "            valid_tokens = tokens.input_ids != base_tokenizer.pad_token_id\n",
        "            replace_pct = args.pct_words_masked * (args.span_length / (args.span_length + 2 * args.buffer_size))\n",
        "\n",
        "            # replace replace_pct of input_ids with random tokens\n",
        "            random_mask = torch.rand(tokens.input_ids.shape, device=DEVICE) < replace_pct\n",
        "            random_mask &= valid_tokens\n",
        "            random_tokens = torch.randint(0, base_tokenizer.vocab_size, (random_mask.sum(),), device=DEVICE)\n",
        "            # while any of the random tokens are special tokens, replace them with random non-special tokens\n",
        "            while any(base_tokenizer.decode(x) in base_tokenizer.all_special_tokens for x in random_tokens):\n",
        "                random_tokens = torch.randint(0, base_tokenizer.vocab_size, (random_mask.sum(),), device=DEVICE)\n",
        "            tokens.input_ids[random_mask] = random_tokens\n",
        "            perturbed_texts = base_tokenizer.batch_decode(tokens.input_ids, skip_special_tokens=True)\n",
        "        else:\n",
        "            masked_texts = [tokenize_and_mask(x, span_length, pct, ceil_pct) for x in texts]\n",
        "            perturbed_texts = masked_texts\n",
        "            # replace each <extra_id_*> with args.span_length random words from FILL_DICTIONARY\n",
        "            for idx, text in enumerate(perturbed_texts):\n",
        "                filled_text = text\n",
        "                for fill_idx in range(count_masks([text])[0]):\n",
        "                    fill = random.sample(FILL_DICTIONARY, span_length)\n",
        "                    filled_text = filled_text.replace(f\"<extra_id_{fill_idx}>\", \" \".join(fill))\n",
        "                assert count_masks([filled_text])[0] == 0, \"Failed to replace all masks\"\n",
        "                perturbed_texts[idx] = filled_text\n",
        "\n",
        "    return perturbed_texts\n",
        "\n",
        "\n",
        "def perturb_texts(texts, span_length, pct, ceil_pct=False):\n",
        "    chunk_size = args.chunk_size\n",
        "    if '11b' in mask_filling_model_name:\n",
        "        chunk_size //= 2\n",
        "\n",
        "    outputs = []\n",
        "    for i in tqdm.tqdm(range(0, len(texts), chunk_size), desc=\"Applying perturbations\"):\n",
        "        outputs.extend(perturb_texts_(texts[i:i + chunk_size], span_length, pct, ceil_pct=ceil_pct))\n",
        "    return outputs\n",
        "\n",
        "\n",
        "def drop_last_word(text):\n",
        "    return ' '.join(text.split(' ')[:-1])\n",
        "\n",
        "\n",
        "def _openai_sample(p):\n",
        "    return p + r['choices'][0].text\n",
        "\n",
        "\n",
        "# sample from base_model using ****only**** the first 30 tokens in each example as context\n",
        "def sample_from_model(texts, min_words=55, prompt_tokens=30):\n",
        "    # encode each text as a list of token ids\n",
        "    if args.dataset == 'pubmed':\n",
        "        texts = [t[:t.index(custom_datasets.SEPARATOR)] for t in texts]\n",
        "        all_encoded = base_tokenizer(texts, return_tensors=\"pt\", padding=True).to(DEVICE)\n",
        "    else:\n",
        "        all_encoded = base_tokenizer(texts, return_tensors=\"pt\", padding=True).to(DEVICE)\n",
        "        all_encoded = {key: value[:, :prompt_tokens] for key, value in all_encoded.items()}\n",
        "\n",
        "    if args.openai_model:\n",
        "        # decode the prefixes back into text\n",
        "        prefixes = base_tokenizer.batch_decode(all_encoded['input_ids'], skip_special_tokens=True)\n",
        "        pool = ThreadPool(args.batch_size)\n",
        "\n",
        "        decoded = pool.map(_openai_sample, prefixes)\n",
        "    else:\n",
        "        decoded = ['' for _ in range(len(texts))]\n",
        "\n",
        "        # sample from the model until we get a sample with at least min_words words for each example\n",
        "        # this is an inefficient way to do this (since we regenerate for all inputs if just one is too short), but it works\n",
        "        tries = 0\n",
        "        while (m := min(len(x.split()) for x in decoded)) < min_words:\n",
        "            if tries != 0:\n",
        "                print()\n",
        "                print(f\"min words: {m}, needed {min_words}, regenerating (try {tries})\")\n",
        "\n",
        "            sampling_kwargs = {}\n",
        "            if args.do_top_p:\n",
        "                sampling_kwargs['top_p'] = args.top_p\n",
        "            elif args.do_top_k:\n",
        "                sampling_kwargs['top_k'] = args.top_k\n",
        "            min_length = 50 if args.dataset in ['pubmed'] else 150\n",
        "            outputs = base_model.generate(**all_encoded, min_length=min_length, max_length=200, do_sample=True, **sampling_kwargs, pad_token_id=base_tokenizer.eos_token_id, eos_token_id=base_tokenizer.eos_token_id)\n",
        "            decoded = base_tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
        "            tries += 1\n",
        "\n",
        "    if args.openai_model:\n",
        "        global API_TOKEN_COUNTER\n",
        "\n",
        "        # count total number of tokens with GPT2_TOKENIZER\n",
        "        total_tokens = sum(len(GPT2_TOKENIZER.encode(x)) for x in decoded)\n",
        "        API_TOKEN_COUNTER += total_tokens\n",
        "\n",
        "    return decoded\n",
        "\n",
        "\n",
        "def get_likelihood(logits, labels):\n",
        "    assert logits.shape[0] == 1\n",
        "    assert labels.shape[0] == 1\n",
        "\n",
        "    logits = logits.view(-1, logits.shape[-1])[:-1]\n",
        "    labels = labels.view(-1)[1:]\n",
        "    log_probs = torch.nn.functional.log_softmax(logits, dim=-1)\n",
        "    log_likelihood = log_probs.gather(dim=-1, index=labels.unsqueeze(-1)).squeeze(-1)\n",
        "    return log_likelihood.mean()\n",
        "\n",
        "\n",
        "# Get the log likelihood of each text under the base_model\n",
        "def get_ll(text):\n",
        "    if args.openai_model:\n",
        "        kwargs = { \"engine\": args.openai_model, \"temperature\": 0, \"max_tokens\": 0, \"echo\": True, \"logprobs\": 0}\n",
        "        r = openai.Completion.create(prompt=f\"<|endoftext|>{text}\", **kwargs)\n",
        "        result = r['choices'][0]\n",
        "        tokens, logprobs = result[\"logprobs\"][\"tokens\"][1:], result[\"logprobs\"][\"token_logprobs\"][1:]\n",
        "\n",
        "        assert len(tokens) == len(logprobs), f\"Expected {len(tokens)} logprobs, got {len(logprobs)}\"\n",
        "\n",
        "        return np.mean(logprobs)\n",
        "    else:\n",
        "        with torch.no_grad():\n",
        "            tokenized = base_tokenizer(text, return_tensors=\"pt\").to(DEVICE)\n",
        "            labels = tokenized.input_ids\n",
        "            return -base_model(**tokenized, labels=labels).loss.item()\n",
        "\n",
        "\n",
        "def get_lls(texts):\n",
        "    if not args.openai_model:\n",
        "        return [get_ll(text) for text in texts]\n",
        "    else:\n",
        "        global API_TOKEN_COUNTER\n",
        "\n",
        "        # use GPT2_TOKENIZER to get total number of tokens\n",
        "        total_tokens = sum(len(GPT2_TOKENIZER.encode(text)) for text in texts)\n",
        "        API_TOKEN_COUNTER += total_tokens * 2  # multiply by two because OpenAI double-counts echo_prompt tokens\n",
        "\n",
        "        pool = ThreadPool(args.batch_size)\n",
        "        return pool.map(get_ll, texts)\n",
        "\n",
        "\n",
        "# get the average rank of each observed token sorted by model likelihood\n",
        "def get_rank(text, log=False):\n",
        "    assert args.openai_model is None, \"get_rank not implemented for OpenAI models\"\n",
        "\n",
        "    with torch.no_grad():\n",
        "        tokenized = base_tokenizer(text, return_tensors=\"pt\").to(DEVICE)\n",
        "        logits = base_model(**tokenized).logits[:,:-1]\n",
        "        labels = tokenized.input_ids[:,1:]\n",
        "\n",
        "        # get rank of each label token in the model's likelihood ordering\n",
        "        matches = (logits.argsort(-1, descending=True) == labels.unsqueeze(-1)).nonzero()\n",
        "\n",
        "        assert matches.shape[1] == 3, f\"Expected 3 dimensions in matches tensor, got {matches.shape}\"\n",
        "\n",
        "        ranks, timesteps = matches[:,-1], matches[:,-2]\n",
        "\n",
        "        # make sure we got exactly one match for each timestep in the sequence\n",
        "        assert (timesteps == torch.arange(len(timesteps)).to(timesteps.device)).all(), \"Expected one match per timestep\"\n",
        "\n",
        "        ranks = ranks.float() + 1 # convert to 1-indexed rank\n",
        "        if log:\n",
        "            ranks = torch.log(ranks)\n",
        "\n",
        "        return ranks.float().mean().item()\n",
        "\n",
        "\n",
        "# get average entropy of each token in the text\n",
        "def get_entropy(text):\n",
        "    assert args.openai_model is None, \"get_entropy not implemented for OpenAI models\"\n",
        "\n",
        "    with torch.no_grad():\n",
        "        tokenized = base_tokenizer(text, return_tensors=\"pt\").to(DEVICE)\n",
        "        logits = base_model(**tokenized).logits[:,:-1]\n",
        "        neg_entropy = F.softmax(logits, dim=-1) * F.log_softmax(logits, dim=-1)\n",
        "        return -neg_entropy.sum(-1).mean().item()\n",
        "\n",
        "\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "tra3gxP9I5Bj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}